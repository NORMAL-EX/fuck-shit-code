//! # ä»£ç åˆ†æå™¨
//! 
//! æ ¸å¿ƒåˆ†æé€»è¾‘çš„å®ç°ï¼Œè´Ÿè´£åè°ƒå„ä¸ªç»„ä»¶å®Œæˆä»£ç åˆ†æ

use crate::common::find_source_files;
use crate::config::AnalysisConfig;
use crate::error::{AppError, AppResult};
use crate::i18n::{Language, Translator};
use crate::metrics::{MetricFactory, MetricResult};
use crate::parser::{create_parser_for_file, ParseResult};
use colored::*;
use indicatif::{ProgressBar, ProgressStyle};
use rayon::prelude::*;
use std::collections::HashMap;
use std::fs;
use std::path::{Path, PathBuf};
use std::sync::{Arc, Mutex};
use std::time::Duration;

use super::result::{AnalysisResult, FileAnalysisResult};

/// ä»£ç åˆ†æå™¨ä¸»ç»“æ„
pub struct CodeAnalyzer {
    /// ç¿»è¯‘å™¨å®ä¾‹
    translator: Translator,
    
    /// æ˜¯å¦é™é»˜æ¨¡å¼
    silent: bool,
    
    /// åº¦é‡å·¥å‚
    metric_factory: MetricFactory,
}

impl CodeAnalyzer {
    /// åˆ›å»ºæ–°çš„ä»£ç åˆ†æå™¨å®ä¾‹
    /// 
    /// # Returns
    /// * `Self` - æ–°çš„åˆ†æå™¨å®ä¾‹
    pub fn new() -> Self {
        let translator = Translator::new(Language::ZhCN);
        let metric_factory = MetricFactory::new(translator.clone());
        
        CodeAnalyzer {
            translator,
            silent: false,
            metric_factory,
        }
    }
    
    /// è®¾ç½®è¯­è¨€
    /// 
    /// # Arguments
    /// * `language` - è¯­è¨€è®¾ç½®
    pub fn set_language(&mut self, language: Language) {
        self.translator = Translator::new(language);
        self.metric_factory = MetricFactory::new(self.translator.clone());
    }
    
    /// è®¾ç½®é™é»˜æ¨¡å¼
    /// 
    /// # Arguments
    /// * `silent` - æ˜¯å¦é™é»˜
    pub fn set_silent(&mut self, silent: bool) {
        self.silent = silent;
    }
    
    /// ä½¿ç”¨é…ç½®è¿›è¡Œåˆ†æ
    /// 
    /// # Arguments
    /// * `path` - åˆ†æè·¯å¾„
    /// * `config` - åˆ†æé…ç½®
    /// 
    /// # Returns
    /// * `AppResult<AnalysisResult>` - åˆ†æç»“æœ
    pub fn analyze_with_config(
        &self,
        path: &Path,
        config: &AnalysisConfig,
    ) -> AppResult<AnalysisResult> {
        // éªŒè¯è·¯å¾„
        self.validate_path(path)?;
        
        // å¤„ç†å•æ–‡ä»¶æƒ…å†µ
        if path.is_file() {
            return self.analyze_single_file(path);
        }
        
        // æœç´¢æºæ–‡ä»¶
        let files = self.find_files(path, config)?;
        
        // æ£€æŸ¥æ˜¯å¦ä¸ºç©ºé¡¹ç›®
        if files.is_empty() {
            return Ok(self.create_empty_result());
        }
        
        // åˆ†ææ–‡ä»¶
        let file_results = self.analyze_files_parallel(&files)?;
        
        // æ±‡æ€»ç»“æœ
        self.aggregate_results(file_results)
    }
    
    /// ä½¿ç”¨æ’é™¤æ¨¡å¼è¿›è¡Œåˆ†æï¼ˆå‘åå…¼å®¹ï¼‰
    /// 
    /// # Arguments
    /// * `path` - åˆ†æè·¯å¾„
    /// * `include_patterns` - åŒ…å«æ¨¡å¼
    /// * `exclude_patterns` - æ’é™¤æ¨¡å¼
    /// 
    /// # Returns
    /// * `AppResult<AnalysisResult>` - åˆ†æç»“æœ
    pub fn analyze_with_excludes(
        &self,
        path: &Path,
        include_patterns: &[String],
        exclude_patterns: &[String],
    ) -> AppResult<AnalysisResult> {
        let config = AnalysisConfig {
            include_patterns: include_patterns.to_vec(),
            exclude_patterns: exclude_patterns.to_vec(),
            ..Default::default()
        };
        
        self.analyze_with_config(path, &config)
    }
    
    /// éªŒè¯è·¯å¾„æœ‰æ•ˆæ€§
    /// 
    /// # Arguments
    /// * `path` - è¦éªŒè¯çš„è·¯å¾„
    /// 
    /// # Returns
    /// * `AppResult<()>` - éªŒè¯ç»“æœ
    fn validate_path(&self, path: &Path) -> AppResult<()> {
        if !path.exists() {
            return Err(AppError::FileNotFound(path.to_path_buf()));
        }
        Ok(())
    }
    
    /// æŸ¥æ‰¾æºæ–‡ä»¶
    /// 
    /// # Arguments
    /// * `path` - æœç´¢è·¯å¾„
    /// * `config` - é…ç½®
    /// 
    /// # Returns
    /// * `AppResult<Vec<PathBuf>>` - æ‰¾åˆ°çš„æ–‡ä»¶åˆ—è¡¨
    fn find_files(&self, path: &Path, config: &AnalysisConfig) -> AppResult<Vec<PathBuf>> {
        if !self.silent {
            self.print_search_progress();
        }
        
        let files = find_source_files(
            path,
            &config.include_patterns,
            &config.exclude_patterns,
            |count| {
                if !self.silent {
                    self.update_search_progress(count);
                }
            },
        )?;
        
        if !self.silent {
            self.print_files_found(files.len());
        }
        
        Ok(files)
    }
    
    /// æ‰“å°æœç´¢è¿›åº¦
    fn print_search_progress(&self) {
        print!("ğŸ” {}", self.translator.translate("analyzer.searching_files"));
    }
    
    /// æ›´æ–°æœç´¢è¿›åº¦
    /// 
    /// # Arguments
    /// * `count` - å½“å‰æ–‡ä»¶æ•°
    fn update_search_progress(&self, count: usize) {
        print!(
            "\rğŸ” {} {}",
            self.translator.translate("analyzer.searching_files"),
            count
        );
    }
    
    /// æ‰“å°æ‰¾åˆ°çš„æ–‡ä»¶æ•°
    /// 
    /// # Arguments
    /// * `count` - æ–‡ä»¶æ•°é‡
    fn print_files_found(&self, count: usize) {
        println!(
            "\r{}\rğŸ“‚ {}: {}",
            " ".repeat(80),
            self.translator.translate("analyzer.files_found"),
            count
        );
    }
    
    /// åˆ›å»ºç©ºé¡¹ç›®ç»“æœ
    /// 
    /// # Returns
    /// * `AnalysisResult` - ç©ºç»“æœ
    fn create_empty_result(&self) -> AnalysisResult {
        if !self.silent {
            self.print_empty_project_message();
        }
        
        AnalysisResult {
            code_quality_score: 0.0,
            metrics: HashMap::new(),
            files_analyzed: vec![],
            total_files: 0,
            total_lines: 0,
            is_empty: true,
        }
    }
    
    /// æ‰“å°ç©ºé¡¹ç›®æ¶ˆæ¯
    fn print_empty_project_message(&self) {
        println!();
        println!("  {}", "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—".bright_yellow());
        println!("  {}", "â•‘       ğŸœï¸  è’èŠœä»£ç æ£€æµ‹å™¨  ğŸœï¸         â•‘".bright_yellow());
        println!("  {}", "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•".bright_yellow());
        println!();
        
        match self.translator.get_language() {
            Language::ZhCN => self.print_empty_message_zh(),
            Language::EnUS => self.print_empty_message_en(),
        }
        
        println!();
    }
    
    /// æ‰“å°ä¸­æ–‡ç©ºé¡¹ç›®æ¶ˆæ¯
    fn print_empty_message_zh(&self) {
        println!("  {}", "ğŸ˜… æ£€æµ‹åˆ°ä¸€ç‰‡è’èŠœ...".bright_cyan());
        println!("  {}", "ğŸ“­ è¿™é‡Œç©ºç©ºå¦‚ä¹Ÿï¼Œè¿ä¸€è¡Œä»£ç éƒ½æ²¡æœ‰ï¼".yellow());
        println!();
        println!("  {}", "å»ºè®®ï¼š".bright_magenta());
        println!("  {}", "1. ğŸ¯ å¿«å»å†™ç‚¹ä»£ç å§ï¼Œä¸ç„¶æˆ‘æ²¡ä¸œè¥¿å¯ä»¥åæ§½äº†".green());
        println!("  {}", "2. ğŸ’¡ æˆ–è€…æ£€æŸ¥ä¸€ä¸‹è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Ÿ".green());
        println!("  {}", "3. ğŸ¤” ä¹Ÿå¯èƒ½æ˜¯æ’é™¤è§„åˆ™å¤ªä¸¥æ ¼äº†ï¼Ÿ".green());
        println!();
        println!("  {}", "ğŸ’­ è®°ä½ï¼šç©ºçš„é¡¹ç›®æ˜¯æœ€å¹²å‡€çš„ï¼Œä½†ä¹Ÿæ˜¯æœ€æ²¡ç”¨çš„ï¼".bright_blue());
    }
    
    /// æ‰“å°è‹±æ–‡ç©ºé¡¹ç›®æ¶ˆæ¯
    fn print_empty_message_en(&self) {
        println!("  {}", "ğŸ˜… Detected a wasteland...".bright_cyan());
        println!("  {}", "ğŸ“­ It's empty here, not even a single line of code!".yellow());
        println!();
        println!("  {}", "Suggestions:".bright_magenta());
        println!("  {}", "1. ğŸ¯ Go write some code, or I have nothing to roast!".green());
        println!("  {}", "2. ğŸ’¡ Or check if the path is correct?".green());
        println!("  {}", "3. ğŸ¤” Maybe the exclusion rules are too strict?".green());
        println!();
        println!("  {}", "ğŸ’­ Remember: Empty projects are the cleanest, but also the most useless!".bright_blue());
    }
    
    /// åˆ†æå•ä¸ªæ–‡ä»¶
    /// 
    /// # Arguments
    /// * `path` - æ–‡ä»¶è·¯å¾„
    /// 
    /// # Returns
    /// * `AppResult<AnalysisResult>` - åˆ†æç»“æœ
    fn analyze_single_file(&self, path: &Path) -> AppResult<AnalysisResult> {
        // è¯»å–æ–‡ä»¶å†…å®¹
        let content = self.read_file(path)?;
        
        // è§£ææ–‡ä»¶
        let parse_result = self.parse_file(path, &content)?;
        
        // åˆ†ææŒ‡æ ‡
        let metrics = self.analyze_metrics(&*parse_result);
        
        // è®¡ç®—å¾—åˆ†
        let file_score = self.calculate_score(&metrics);
        
        // æ”¶é›†é—®é¢˜
        let issues = self.collect_issues(&metrics);
        
        // åˆ›å»ºç»“æœ
        Ok(self.create_single_file_result(
            path,
            file_score,
            metrics,
            issues,
            parse_result.get_total_lines(),
        ))
    }
    
    /// è¯»å–æ–‡ä»¶å†…å®¹
    /// 
    /// # Arguments
    /// * `path` - æ–‡ä»¶è·¯å¾„
    /// 
    /// # Returns
    /// * `AppResult<String>` - æ–‡ä»¶å†…å®¹
    fn read_file(&self, path: &Path) -> AppResult<String> {
        fs::read_to_string(path)
            .map_err(|e| AppError::Io(e))
    }
    
    /// è§£ææ–‡ä»¶
    /// 
    /// # Arguments
    /// * `path` - æ–‡ä»¶è·¯å¾„
    /// * `content` - æ–‡ä»¶å†…å®¹
    /// 
    /// # Returns
    /// * `AppResult<Box<dyn ParseResult>>` - è§£æç»“æœ
    fn parse_file(&self, path: &Path, content: &str) -> AppResult<Box<dyn ParseResult>> {
        let parser = create_parser_for_file(path);
        parser.parse(path, content)
            .map_err(|e| AppError::ParseError(e.to_string()))
    }
    
    /// åˆ†ææŒ‡æ ‡
    /// 
    /// # Arguments
    /// * `parse_result` - è§£æç»“æœ
    /// 
    /// # Returns
    /// * `HashMap<String, MetricResult>` - æŒ‡æ ‡ç»“æœ
    fn analyze_metrics(&self, parse_result: &dyn ParseResult) -> HashMap<String, MetricResult> {
        let metrics = self.metric_factory.create_all_metrics();
        let mut results = HashMap::new();
        
        for metric in metrics {
            let result = metric.analyze(parse_result);
            results.insert(metric.name().to_string(), result);
        }
        
        results
    }
    
    /// è®¡ç®—æ–‡ä»¶å¾—åˆ†
    /// 
    /// # Arguments
    /// * `metrics` - æŒ‡æ ‡ç»“æœ
    /// 
    /// # Returns
    /// * `f64` - å¾—åˆ†
    fn calculate_score(&self, metrics: &HashMap<String, MetricResult>) -> f64 {
        let mut total_score = 0.0;
        let mut total_weight = 0.0;
        
        for result in metrics.values() {
            total_score += result.score * result.weight;
            total_weight += result.weight;
        }
        
        if total_weight > 0.0 {
            total_score / total_weight
        } else {
            0.0
        }
    }
    
    /// æ”¶é›†é—®é¢˜
    /// 
    /// # Arguments
    /// * `metrics` - æŒ‡æ ‡ç»“æœ
    /// 
    /// # Returns
    /// * `Vec<String>` - é—®é¢˜åˆ—è¡¨
    fn collect_issues(&self, metrics: &HashMap<String, MetricResult>) -> Vec<String> {
        metrics.values()
            .flat_map(|result| result.issues.clone())
            .collect()
    }
    
    /// åˆ›å»ºå•æ–‡ä»¶ç»“æœ
    /// 
    /// # Arguments
    /// * `path` - æ–‡ä»¶è·¯å¾„
    /// * `score` - å¾—åˆ†
    /// * `metrics` - æŒ‡æ ‡ç»“æœ
    /// * `issues` - é—®é¢˜åˆ—è¡¨
    /// * `lines` - è¡Œæ•°
    /// 
    /// # Returns
    /// * `AnalysisResult` - åˆ†æç»“æœ
    fn create_single_file_result(
        &self,
        path: &Path,
        score: f64,
        metrics: HashMap<String, MetricResult>,
        issues: Vec<String>,
        lines: usize,
    ) -> AnalysisResult {
        AnalysisResult {
            code_quality_score: score,
            metrics,
            files_analyzed: vec![FileAnalysisResult {
                file_path: path.display().to_string(),
                file_score: score,
                issues,
            }],
            total_files: 1,
            total_lines: lines,
            is_empty: false,
        }
    }
    
    /// å¹¶è¡Œåˆ†æå¤šä¸ªæ–‡ä»¶
    /// 
    /// # Arguments
    /// * `files` - æ–‡ä»¶åˆ—è¡¨
    /// 
    /// # Returns
    /// * `AppResult<Vec<FileAnalysisData>>` - åˆ†ææ•°æ®åˆ—è¡¨
    fn analyze_files_parallel(&self, files: &[PathBuf]) -> AppResult<Vec<FileAnalysisData>> {
        let results = Arc::new(Mutex::new(Vec::new()));
        let progress = self.create_progress_bar(files.len());
        
        // å¹¶è¡Œå¤„ç†æ–‡ä»¶
        files.par_iter().for_each(|file| {
            if let Ok(data) = self.analyze_file_safe(file) {
                let mut res = results.lock().unwrap();
                res.push(data);
            }
            
            if let Some(ref pb) = progress {
                pb.inc(1);
            }
        });
        
        if let Some(pb) = progress {
            pb.finish_and_clear();
        }
        
        Arc::try_unwrap(results)
            .map_err(|_| AppError::Other("Failed to unwrap results".to_string()))?
            .into_inner()
            .map_err(|_| AppError::Other("Failed to get inner mutex".to_string()))
    }
    
    /// åˆ›å»ºè¿›åº¦æ¡
    /// 
    /// # Arguments
    /// * `total` - æ€»æ•°
    /// 
    /// # Returns
    /// * `Option<ProgressBar>` - è¿›åº¦æ¡
    fn create_progress_bar(&self, total: usize) -> Option<ProgressBar> {
        if self.silent {
            return None;
        }
        
        let pb = ProgressBar::new(total as u64);
        pb.set_style(
            ProgressStyle::default_bar()
                .template("{spinner:.green} [{elapsed_precise}] [{bar:40.cyan/blue}] {pos}/{len} ({eta})")
                .unwrap()
                .progress_chars("#>-"),
        );
        pb.enable_steady_tick(Duration::from_millis(100));
        
        Some(pb)
    }
    
    /// å®‰å…¨åœ°åˆ†ææ–‡ä»¶ï¼ˆæ•è·é”™è¯¯ï¼‰
    /// 
    /// # Arguments
    /// * `file` - æ–‡ä»¶è·¯å¾„
    /// 
    /// # Returns
    /// * `AppResult<FileAnalysisData>` - åˆ†ææ•°æ®
    fn analyze_file_safe(&self, file: &PathBuf) -> AppResult<FileAnalysisData> {
        let content = self.read_file(file)?;
        let parse_result = self.parse_file(file, &content)?;
        let metrics = self.analyze_metrics(&*parse_result);
        let issues = self.collect_issues(&metrics);
        
        Ok(FileAnalysisData {
            path: file.clone(),
            metrics,
            issues,
            lines: parse_result.get_total_lines(),
        })
    }
    
    /// æ±‡æ€»åˆ†æç»“æœ
    /// 
    /// # Arguments
    /// * `file_results` - æ–‡ä»¶åˆ†ææ•°æ®
    /// 
    /// # Returns
    /// * `AppResult<AnalysisResult>` - æ±‡æ€»ç»“æœ
    fn aggregate_results(&self, file_results: Vec<FileAnalysisData>) -> AppResult<AnalysisResult> {
        let mut total_lines = 0;
        let mut all_metrics: HashMap<String, Vec<MetricResult>> = HashMap::new();
        let mut files_analyzed = Vec::new();
        
        // å¤„ç†æ¯ä¸ªæ–‡ä»¶çš„ç»“æœ
        for data in file_results {
            let file_score = self.calculate_score(&data.metrics);
            
            files_analyzed.push(FileAnalysisResult {
                file_path: data.path.display().to_string(),
                file_score,
                issues: data.issues,
            });
            
            // æ”¶é›†æŒ‡æ ‡
            for (name, result) in data.metrics {
                all_metrics.entry(name).or_insert_with(Vec::new).push(result);
            }
            
            total_lines += data.lines;
        }
        
        // è®¡ç®—å¹³å‡æŒ‡æ ‡
        let aggregated_metrics = self.calculate_average_metrics(all_metrics);
        
        // è®¡ç®—æ€»ä½“è¯„åˆ†
        let code_quality_score = self.calculate_score(&aggregated_metrics);
        
        let total_files = files_analyzed.len();
        
        Ok(AnalysisResult {
            code_quality_score,
            metrics: aggregated_metrics,
            files_analyzed,
            total_files,
            total_lines,
            is_empty: false,
        })
    }
    
    /// è®¡ç®—å¹³å‡æŒ‡æ ‡
    /// 
    /// # Arguments
    /// * `all_metrics` - æ‰€æœ‰æŒ‡æ ‡
    /// 
    /// # Returns
    /// * `HashMap<String, MetricResult>` - å¹³å‡æŒ‡æ ‡
    fn calculate_average_metrics(
        &self,
        all_metrics: HashMap<String, Vec<MetricResult>>,
    ) -> HashMap<String, MetricResult> {
        let mut aggregated = HashMap::new();
        
        for (name, results) in all_metrics {
            if !results.is_empty() {
                let avg_score = results.iter()
                    .map(|r| r.score)
                    .sum::<f64>() / results.len() as f64;
                
                let first = &results[0];
                
                aggregated.insert(name, MetricResult {
                    score: avg_score,
                    weight: first.weight,
                    description: first.description.clone(),
                    issues: vec![],
                });
            }
        }
        
        aggregated
    }
}

/// æ–‡ä»¶åˆ†ææ•°æ®
#[derive(Debug)]
struct FileAnalysisData {
    /// æ–‡ä»¶è·¯å¾„
    path: PathBuf,
    
    /// æŒ‡æ ‡ç»“æœ
    metrics: HashMap<String, MetricResult>,
    
    /// é—®é¢˜åˆ—è¡¨
    issues: Vec<String>,
    
    /// ä»£ç è¡Œæ•°
    lines: usize,
}